### 组会报告的resnet的正确率的代码问题
经张起检查，在产生数据一环节出现问题。
在gpu上输入以下代码，发现`corrects = np.array(dataset.corrects, dtype = int)`这一句应该改为`corrects = np.array(dataset.corrects, dtype = bool)`。因为在source的Dataset.py中，corrects是bool形式，转化为int形式时True->1，False->0。产生数据时`subset = Subset(dataset, np.arange(len(dataset))[corrects]) # all correct particles`最后就只取出了第0/1张图片。所以相当于只对两张图片作了拟合。
```python
ssh gpu04
cd zhujianying/Compressed_Sensing/output/
ls
python3
import numpy as np
a = np.load('res_Meta_Final_0-10K_correct.npy', allow_pickle = True, mmap_mode = 'r')
a.shape
a.dtype
t = [np.allclose(a[0], a[i]) for i in range(9972)]
len(t) # 9972
sum(t) # 4918
```
修改后网络的正确率又回到了50%左右（输入是有噪声图片的残差）。
### 是否进行k-fold cross validation
关于组会上讨论的k-fold交叉验证，在网上我搜到的说法是：对神经网络不进行交叉验证的理由是：
1. 训练神经网络的计算代价很大，k-fold cv则需要训练k个神经网络
2. 在用神经网络时，我们往往有极大量的数据，在这种情况下，我们没有必要去通过cross validation来充分利用数据

### 6.17组会任务记录
#### 目前可以做的
改k-fold: 对Dataset操作下标：生成一个np.arange(len(dataset))，然后随机砍成10份，然后你每次（随机？循环？）选取一份，用torch的Subset生成validation dataset，然后剩下的9份拼一起也用Subset生成training dataset。 memmap？
继续调一调看看正确率咋样...
确认用的Res50有多少个参数`print("resnet50 have {} paramerters in total".format(sum(x.numel() for x in resnet50.parameters())))`(numel表示含有多少element)
改代码：training set里加入validation set，做k fold。---想调用sklearn的包实现，但是集群上没有安装sklearn，正在询问张起能否安装。（10-fold: 先随机划分成10份，每次leave one out作为validation。如果用list列出所有的train-validation的可能组合的话会存储原先10倍的数据，或者要写一个list存下每一份，每次取一份validation，其余九份拼成training，代码很丑陋。所以想要调包）
问一下名旭昨天说的如何构造正确的数据集。
#### 推后
用一个蛋白质训练网络，在另一个蛋白质上测试正确率，看能否区分（比如用fun30训练，用proteasome测试）。
网络结构换小，比如Res20，VGG。做神经网络的可视化（尤其是浅层），看看它到底学到了什么。
Open Set/PU Learning，看看别人做了什么。（报告论文前先在群里发一下）
换一下数据集的正确率50%->30%/70%。
#### 经验
在人工数据集上跑出好结果再测试真实数据。
如果进行了多进程并行计算的话，要先random split，再分布到不同device上，不然不同的device会进行不同的random split，training set和testing set会混在一起。
组会报告时要放可视化后的结果，不要放个正确率就结束了，这样无法判断这个结果怎么样，为什么这样。