### 本周完成实验
#### 实验1: 目前训练的网络正确率为87%，拿神经网络判断为正确的数据重构，比较分辨率
##### 实验结果
取batch_size = 50, epoch_num = 1（该实验具有一定随机性，每次的结果有一定差异，但大小关系一致）。
|  | cng | fun30 | proteasome |
| ---- |  ---- | ---- | ---- |
| 10K 50%错误率 所有颗粒 | 8.45A | 17.6A | 7.82A |
| 10K 50%错误率 所有正确颗粒 | 7.28A | 10.56A | 4.48A |
| 10K 50%错误率 带入ground truth计算残差，用神经网络判断为正确的颗粒重构 | 7.04A | 11.00A | 6.87A |
| 10K 50%错误率 带入50%错误率的10K的颗粒重构出的三维结构计算残差，用神经网络判断为正确的颗粒重构 | 7.54A | 15.52A | 7.16A |
##### 实验结论
无论是带入ground truth计算残差（测试集上正确率为87%）再用神经网络判断为正确的颗粒重构还是带入50%错误率的10K的颗粒重构出的三维结构计算残差（重构一次筛一次正确率为70%左右）再用神经网络判断为正确的颗粒重构，都比仅仅用50%错误率的所有颗粒重构分辨率更高。但是考虑到实际数据的错误率未必高如50%，仅用70%正确率的判断方法未必能得到更好的效果。

#### 实验2:把网络的筛选加入重构过程
重构一遍筛一遍。首先用50%错误率的10K的数据重构出（有误差的带噪）三维结构，用此结构计算残差，zero padding后用三种蛋白质训练出的神经网络做判断。
##### 实验结果
表格中数据为重构后的分辨率与筛选时的正确率。
|  | cng | fun30 | proteasome |
| ---- |  ---- | ---- | ---- |
| 0次(用0.5正确率所有颗粒重构) | 8.5A | 18.85A | 7.82A |
| 1次 | 7.54A 78.24%. | 12.57A, 67.77% | 6.87A, 69.42% |
| 2次 | 7.54A 84.93% | 13.20A, 72.35% | 7.01A, 70.78% |
##### 实验结果分析
可以看到，对于50%正确率的数据与用其训练的网络，第二次筛选其分辨率降低（数值升高），正确率相近，有极小的提升。针对目前的50%正确率的数据，最好的方法是重构一遍筛选一遍。

#### 实验3:用同一个神经网络训练三种蛋白质
把三种蛋白质的残差混合，作为新的dataset，一起给神经网络训练。由于三种蛋白质残差大小不同，对较小的残差作zero padding（因为混合后以batch形式输入，pytorch要求batch的大小必须统一，ResNet50网络由于全局平均池化层的存在可以接受不同大小的输入）。
##### 实验结果
测试集上的average loss: 0.3258, 准确率: 87.05%。
##### 实验结果分析
可能是ResNet50识别出了三种蛋白质残差的共同特征，从而具有“可迁移性”，需要更多实验。
也可能是网络仅仅记住了三种蛋白质残差的各自的特征。

#### 下周TO DO
0. 可视化的实验结果整理并上传CRS。(周一)
1. cs231n训练相关章节补，resnet二分类训练集上损失函数应该接近0，网络未训练到位，调参并汇报结果。(周一、周二)
2. 尝试更多网络，更简单的网络更方便可视化。
3. 调研神经网络如何处理不同大小的输入，代码中的0-padding -> resize?（周三）
4. 做神经网络可迁移性的实验。（周三）
5. 读DeepAlign论文，汇报。（周三）