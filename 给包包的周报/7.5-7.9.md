#### 解决由于“坏颗粒”带来的重构之中的干扰
经过漫长的debug，现在确认程序没有问题。有以下结果：
| | cng | fun30 | proteasome |
| :----: | :----: | :----: | :----: |
| ResNet50 + Mask | 87.55% | 79.30% | 88.10% |
| VGG19 + Mask | 52.15% | - | - |
| ResNet50 + No Mask | 86.10% | 82.05% | 86.75% |
| CNN + Mask | 50.30% | - | - |

表格中正确率为测试集上的正确率，共用了10K个颗粒的残差，训练集与测试集分别占80%与20%，CNN的结构为：`conv->relu->maxpool2d->conv->relu->maxpool2d->fc1->fc2->fc3`,VGG19为无batch normalization的版本。网络经过3个epoch，还未手动调参，三种蛋白质各在10K错误率为50%的数据集上训练（一共三个网络）ResNet50总计需要1小时。
CNN由于未进行全局池化，对不同box size的蛋白质输入需要手动修改网络结构，故为了简便只测试了cng，也足以反应结果。当然该结果差也和网络结构过于简单有关。

可以得到结论：
1. 简单的CNN与VGG19对挑选坏颗粒的二分类任务不work，ResNet50则work的比较好。可以再探索其他分类网络，如VGG32，ResNet100等等。
2. 是否加Mask对区分坏颗粒的残差作用不大。

#### 在重构过程中加入训练好的神经网络
涉及残差$CPx-T^{-1}b$中的三维model$x$的更新方式，因此有两种思路：
1. 对数据集中的所有颗粒select一遍，再神经网络判断为正确的颗粒重构一遍。（可以直接调用source中的reconstruct函数）——test_recon_select.py
2. 每个batch会产生一个梯度，从而更新一次$x$。也可以在每个batch内select。一个问题：是否设置下界？如果batch内所有颗粒都被判断为错误，那会损失很多信息。（需要重新写reconstruct函数）
首先实现思路1。

#### 下周任务
TODO：
1. 在重构过程中加入网络，观察结果。
2. 神经网络可视化，观察它的特征图。
3. 按照张起的建议，可以写一个循环/脚本，让程序跑不同的网络，看看更深的网络与不同的网络结构对ml select问题是否work。
4. 再次调研冷冻电镜领域于神经网络相关的论文。主题：看他人怎么preprocess，怎么处理强噪声。
5. 仔细阅读之前调研到的DeepAlign论文并做笔记（之后组会汇报）。
6. 做更精确（接近实际数据的）的实验：
- 错误颗粒比例改为0.3，根据DeepAlign论文，30%的错误率更接近实际数据。
- 调整网络结构，手动调参。
7. 现在的程序没有问题，正确率可观，按照之前的想法继续往下做：调研open set recognition、positive unlabeled learning，复现结果并尝试运用于我们的问题。
8. 调研Deep Learning中对应问题：mnist只给偶数样本，要求区分奇偶样本；GAN中有错误样本（人脸中混入了狗脸）能否生成人脸。关键词：positive unlabeled learning, open set recognition
min-max：可以产生loss函数，最大化不同类间距离，最小化样本内距离，使得类内点距离尽可能大以防止坍塌。
