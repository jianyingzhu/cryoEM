### 代码部分wait to do：
1. 看training set shuffle改为true跑 对比实验结果
2. 三种蛋白质train一个网络
3. recon_select debug -epoch改为20试试 -没用
4. Save dict确认，加入recon的程序

1. save net.parameters and print feature maps
2. reconstruct里思路是重构一遍select一遍，如果在batch内select，是否设置下界？如果一个particle都不用？
3. 增加print出多少人工设置的错误颗粒

如果用同一个神经网络训练三种蛋白质（同时对三种蛋白质进行错误颗粒的挑选），哪种逻辑比较好：
1. 定义一个网络，每种蛋白质train一遍test一遍，下一个蛋白质接着上一次的继续train一遍test一遍，以此类推。
2. 把三种蛋白质的残差随机混合，作为新的dataset，train一遍test一遍。
我和zdh都觉得2比较科学，故根据思路2进行实验。

#### 在重构过程中加入训练好的神经网络
涉及残差$CPx-T^{-1}b$中的三维model$x$的更新方式，因此有两种思路：
1. 对数据集中的所有颗粒select一遍，再神经网络判断为正确的颗粒重构一遍。（可以直接调用source中的reconstruct函数）——test_recon_select.py
2. 每个batch会产生一个梯度，从而更新一次$x$。也可以在每个batch内select。一个问题：是否设置下界？如果batch内所有颗粒都被判断为错误，那会损失很多信息。（需要重新写reconstruct函数）
首先实现思路1。

#### 下周任务
TODO：
0. 现在是不同的蛋白质训练不同的网络，如果都用同一个网络训练，正确率如何？
1. 在重构过程中加入网络，观察结果。
2. 神经网络可视化，观察它的特征图。
3. 按照张起的建议，可以写一个循环/脚本，让程序跑不同的网络，看看更深的网络与不同的网络结构对ml select问题是否work。
4. 再次调研冷冻电镜领域于神经网络相关的论文。主题：看他人怎么preprocess，怎么处理强噪声。
5. 仔细阅读之前调研到的DeepAlign论文并做笔记（之后组会汇报）。
6. 做更精确（接近实际数据的）的实验：
- 错误颗粒比例改为0.3，根据DeepAlign论文，30%的错误率更接近实际数据。
- 调整网络结构，手动调参。
7. 现在的程序没有问题，正确率可观，按照之前的想法继续往下做：调研open set recognition、positive unlabeled learning，复现结果并尝试运用于我们的问题。
8. 调研Deep Learning中对应问题：mnist只给偶数样本，要求区分奇偶样本；GAN中有错误样本（人脸中混入了狗脸）能否生成人脸。关键词：positive unlabeled learning, open set recognition
min-max：可以产生loss函数，最大化不同类间距离，最小化样本内距离，使得类内点距离尽可能大以防止坍塌。

- 
