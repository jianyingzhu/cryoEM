Todo: 
1. 一个是去分析proteasome的那个loss histogram为啥是两个峰，是否跟优势取向有关。另外cng跟proteasome一样有优势取向，但是没有两个峰。。。
1. 集群上面的~/zhangqi/Compressed_Sensing/outpu/里面，有一个res_corr.npy和res_wrong.npy，分别是cng数据下，用ground truth对一半正确投影（其实是512个）和一半错误投影（其实是488个）给出的残差图片，就是Ax-b，第一个是512*160*160数组，第二个是488*160*160数组，可以用numpy的load函数读出来。现在问题就变成，怎么样分类这两组数据，仅仅用loss最多就分出70%的正确率出来，我试过了。相当于loss这个特征不够用，看你能不能找更多的特征。实在不行深度学习一下，看看深度学习能不能对这种东西work。
1. 真值带进去计算cv loss，与估计wi的cv loss做比较。验证：那我对你4月1日组会所说的，cv-based weighted L2 loss 的重构结果，会比原先普通重构的 cv loss 更小。换言之，你 claim 了这样一个结论：从 half set A 里选出部分图像，重构出的模型，其投影会非常类似 half set B 里的部分图像。这个结论实在太反直觉了。
1. 乘一个beta_i，或者$u_i$改为$|u_i|$。不用softmax层，直接投影。一篇论文提到，$min_x \frac{1}{2}||x-y||^2 s.t. x\geq 0, 1^Tx=1$有精确解。'Efficient Projections onto the ℓ1-Ball for Learning in High Dimensions'。

- 真值带进去计算cv loss，与估计wi的cv loss做比较。
2K的颗粒，错误率为50%：
1. 用weighted L2重构，cv loss
2. 用2K的颗粒中的1K个正确颗粒做普通的L2重构，cv loss

- 程序运行的时候有它自己的路径。比如你的A目录，打开一个终端，然后python blabla.py，这个程序就在A目录下运行，这个时候相对路径就是从A目录开始。如果你是B目录，打开一个终端，然后python blabla.py，这个程序就在B目录下运行，这个时候你之前work的相对路径，现在可能就不work。相对路径不是相对于程序py文件的路径，而是相对于你运行这个程序的时候的路径。kernels里面有这样的话：
`module = cp.RawModule(path = os.path.dirname(__file__) + '/kernel.cubin', backend = 'nvcc')`。这个`dirname(__file__)`就是获得当前程序所在的目录，这样就避免了相对路径问题。
- `sys.path`就是系统的PATH环境变量，不是运行程序的路径。运行程序的路径是`os.getcwd()`。
- 运行程序不是非要在.py文件当前所在的目录，比如我在C盘打开一个终端，然后`python D:/test.py`。
- `__file__`用来获得模块所在的路径。
按相对路径./test.py来执行，则打印得到的是相对路径，按绝对路径执行则得到的是绝对路径。
而按用户目录来执行（~/practice/test.py），则得到的也是绝对路径（~被展开）。
- `os.path.join(path1, path2, ...)`会从第一个以”/”开头的参数开始拼接，之前的参数全部丢弃。
- cupy.cuda.memory.OutOfMemoryError: Out of memory allocating 262144000 bytes (allocated so far: 13682483712 bytes): 显存爆了。可是尝试的方法：调小batch size。
- OT: 将输入图片的数组看作质量，P[i, j]: 从i-th到j-th的质量；x[i], x[j]: i-th, j-th的坐标；t时刻P[i, j]放在(1-t)x[i]+t*x[j]的位置。所以通过OT算法得出P之后，每一帧都需O(n^2)的运算量枚举i,j（n=240^3，格点数），太大。
- 对于长度为n的数组，快速傅立叶变换所需复杂度为O(nlgn)



