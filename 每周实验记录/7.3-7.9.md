### 代码部分wait to do：
1. save net.parameters and print feature maps
2. reconstruct里思路是重构一遍select一遍，如果在batch内select，是否设置下界？如果一个particle都不用？
3. 增加print出多少人工设置的错误颗粒

- 
```python
a = np.arange(27).reshape((3,3,3))
print(a[0]) # same as a[0, :, :]
a[0] = np.ones((3,3))
print(a) # no error
```
- 这次在几个bug上卡了很久，教训：1.一定要等程序的一个功能测试完没有问题再增加其他功能。2.debug一定要舍得删代码。
- `/usr/local/lib/python3.7/dist-packages/mrcfile/mrcinterpreter.py:219: RuntimeWarning: Unrecognised machine stamp: 0x00 0x00 0x00 0x00
  warnings.warn(str(err), RuntimeWarning)`是mrc文件head造成的。
- shift+option+光标选中多行可以形成长光标，多行操作。
- / 根目录 . 当前目录
- 在gpu上做小程序的调试，gpu上的torch版本过低，用docker镜像中的版本：
```python
ssh gpu03 # gpu00没有计算能力，01-06都可
pip3 list # 列出所有python3的package，可以看到torch版本过低
docker image ls
docker help # 查看docker的帮助
docker image help # 也可以看docker image命令的帮助
docker run -it IMAGEID # it指interactive，-it后也可以加—gpus all
#此时进入了docker的沙盒环境里
pip3 list
python3
import torch
# your code
exit() # 退出python3环境
exit # 退出docker沙盒环境
```
- 求mask最大半径的另一种方法(numpy有indices函数，可以不用mgrid函数)：
```python
import numpy as np
box_size = 4
# radius = np.sum((np.indices((box_size, box_size, box_size)) - box_size // 2) ** 2, axis = 0)
# np.sqrt(radius.max())
x = np.indices((box_size, box_size, box_size)) # x.shape = (3, 4, 4, 4)
t = (np.indices((box_size, box_size, box_size)) - box_size // 2) ** 2 # t.shape = (3, 4, 4, 4)
radius = np.sum(t, axis = 0) # radius.shape = (4, 4, 4)
max_radius = radius.max() # 12 
index = np.unravel_index(np.argmax(radius), radius.shape) # (0, 0, 0)
```
- `np.sum(axis = x)`会对x维度求和，从而x维度求和后就消失了。
```python
print(np.sum(np.ones((2,3)), axis = 0))
# [2. 2. 2.]
```
- numpy中 C order与F order的区别是什么？多维数组在内存中的存储顺序问题。order参数的C和F是numpy中数组元素存储区域的两种排列格式，即C语言格式和Fortran语言格式。以一个二维数组a[2][2]为例，在C语言中，其在内存中存储为`a[0][0] a[0][1] a[1][0] a[1][1]`，而在Fortran语言中，其顺序为`a[0][0] a[1][0] a[0][1] a[1][1]`。总结：C-order是最后一根轴（最里层的括号）连续存储，F-order是第一根轴连续存储。
- numpy中求数组最大元素与最大元素下标的方法：
```python
import numpy as np
s = np.random.randn(3, 4)
ind = np.unravel_index(np.argmax(s), s.shape)
# np.argmax(): return the indices of the maximum values along an axis.
print(ind) # the indices of max value
print(s.max()) # the max value
```
- k-fold的代码：
```python
k_fold = 10
print('Randomly split training set into k_fold(10) parts, and select one as validation set and leave else as training set.')
n = len(training_set)
index = np.random.permutation(n)
step = (n + k_fold - 1) // k_fold # ceil(n / k_fold)
for i in range(k_fold):
    l = i * step
    r = min(n, (i + 1) * step)
    one = index[l:r]
    leave_one_out = np.concatenate((index[r:], index[:l]))
    validation_loader = DataLoader(dataset = Subset(training_set, one), batch_size = batch_size, pin_memory = True, num_workers = 1)
    training_loader = DataLoader(dataset = Subset(training_set, leave_one_out), batch_size = batch_size, pin_memory = True, num_workers = 1)
    for epoch in range(epoch_num):
        pass
```
- import本文件夹下其他文件：
```python
import os
sys.path.append(os.path.dirname(__file__))
from xxx import xxx
```
- 之后debug把network的output的size打印出来。
- 仔细看了一遍pytorch的ResNet50的源码。我调用的Res50存在以下几个问题：
1. 我们输入的是灰度图像，pytorch默认输入彩色图像。解决方法参考[ResNet训练单通道图像分类网络（Pytorch）](https://blog.csdn.net/jiacong_wang/article/details/105631229):
```python
from torchvision import models
resnet50 = models.resnet50(num_classes = 2)
resnet50.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) #第一个参数由3改为1
```
2. 作为分类任务，num classes没有改为2。改为`resnet50 = models.resnet50(num_classes = 2)`
3. 一个疑问：为什么Pytorch的resnet可以对不同大小的图片都work？因为存在`self.avgpool = nn.AdaptiveAvgPool2d((1, 1))`层。ResNet预先训练的模型使用224x224的图像大小。
4. ResNet50的源码的逻辑存在`Downloads/resnet50.md`中。


- source的`Stack.get_image(i_slc)`和list/ndarray的slice有区别，它是创建并返回一个新的Image。
- 快捷键：在FTP中可以输入文件前几个字母，光标选中会自动跳转，按enter即可进入。
- 删除的代码：
```python
from cupy.fft import fftshift
def get_radius_along_quat(model_path, quats, threshold):
    # project the model along given quats, compute the largest index radius of the non-zero element
    with mrcfile.mmap(model_path, permissive = True, mode = 'r') as mrc:
        mask3d = cp.array(mrc.data > threshold, dtype = cp.float64)
    vol = Volume(data = mask3d)
    img = project(vol, quats, box_size, box_size)
    img = fftshift(img.data_RL)
    radius = cp.where(img >= 0.5, R, 0)
    return cp.max(radius)
```
- 网络的最后不需要添加softmax层，因为`torch.nn.CrossEntropyLoss`等价于Softmax+NLL(Negative Log Likelihood)。由例子可见label也不需要改成one hot向量。参考资料见：[Pytorch详解NLLLoss和CrossEntropyLoss](https://blog.csdn.net/qq_22210253/article/details/85229988)，[Pytorch里的CrossEntropyLoss详解](https://www.cnblogs.com/marsggbo/p/10401215.html)以及pytorch官方文档。
```python
input = torch.randn(10, 2, requires_grad=True) # torch.Size([10, 2])
label = torch.empty(10, dtype=torch.long).random_(2) # torch.Size([10])
# softmax + nll
input1 = torch.nn.Softmax(dim = 1)(input) # sum of rows is equal to 1
input2 = torch.log(input1)
input3 = torch.nn.NLLLoss()(input2, label)
# cross entropy loss, output == input3
output = torch.nn.CrossEntropyLoss()(input, label) # torch.Size([])
```
- 一般情况下，二维时，`dim = 0`表示对列，`dim=1`表示对行。
```python
# a = torch.randn(4, 4)
# print(a)
# print(torch.max(a, 0)) # col
# print(torch.max(a, 1)) # row
```
- `nn.functional.xxx`vs`nn.xxx`: PyTorch官方推荐，具有学习参数的（例如，conv2d, linear, batch_norm)采用nn.Xxx方式，没有学习参数的（例如，maxpool, loss func, activation func）等根据个人选择使用nn.functional.xxx或者nn.Xxx方式。但关于dropout，强烈推荐使用nn.Xxx方式，因为一般情况下只有训练阶段才进行dropout，在eval阶段都不会进行dropout。使用nn.Xxx方式定义dropout，在调用model.eval()之后，model中所有的dropout layer都关闭，但以nn.function.dropout方式定义dropout，在调用model.eval()之后并不能关闭dropout。结论：能用`nn.Xxx`情况下尽量使用，不行再换`nn.functional.xxx`。`nn.functional.xxx`更加的灵活(更加接近底层），你可以在其基础上定义出自己想要的功能。
- `from typing import Type, Any, Callable, Union, List, Optional`，typing里的类型可以使得python类似于C++那样运行。`def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:`，在变量后面加上：type，在函数最后加上-> type。这里的type没有约束能力，只是给vscode/人看的。
- `nn.ReLU()` vs `nn.ReLU(inplace=True)`：
`inplace=True`对计算结果不会有影响。利用in-place计算可以节省内（显）存，同时还可以省去反复申请和释放内存的时间。但是会对原变量覆盖，只要不带来错误就用。
- Mac快捷键：command+Tab
- class里的method一般不改变x，返回method作用在x上的值。
- 1个`float64`是64位的，8个bit。那么$320*320*20$个`float64`共$320*320*20*8 bit = 320*320*20*8/1024 KB = 320*320*20*8/(1024 * 1024) MB$，约为$15M$。
- 32位电脑/64位电脑是指指针的表示位数，32位电脑一个指针有32位，能表示2^32个数，如果内存条为8G，2^32/(2^10)^3 = 4 GB，只能表示4GB的内存地址。
- 修改完能跑通了就上传到CRS对应的Task下，方便之后恢复到上个版本的程序（版本管理）。
- slurm是任务调度系统。
- 杀进程(白色为linux命令)：
```python
cat 27000.err # 27000: job id
# srun: error: gpu03: task 0: Exited with exit code 1
ssh gpu03
# Last login: Mon Jul  5 17:18:36 2021 from gpu00
nvidia-smi
# a big table 1(next block)
ps aux | grep 142213 # ps aux: 查看所有进程  grep:搜索  |：管道，把前一个命令的输出作为后一个命令的输入   142213: Process ID，进程ID。该行命令可以看到任务的名字。
# root     142213  101  0.7 46873788 3051312 ?    Rl   19:58  14:59 python3 test_ml_select.py
# thunder+ 144302  0.0  0.0 112736   996 pts/1    S+   20:13   0:00 grep --color=auto 142213
ps aux | grep 142835
# 略
ps aux | grep 143208
# 略
kill 143208 # 可能是有人没经过slurm偷偷跑的程序
nvidia-smi
# a big table 2(next block)，可以看到143208确实被杀掉了
docker container ls
# chart 1
docker stop 8862 # 8862:container id的前几位，能够识别出来就行
# 8862
docker stop e4b
# e4b
nvidia-smi
# 发现所有进程终止了
```
- a big table 1:
Mon Jul  5 20:12:07 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   60C    P0   138W / 300W |  23591MiB / 32510MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   36C    P0    55W / 300W |    440MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   32C    P0    41W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   35C    P0    42W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0    142213      C   python3                                    11789MiB |
|    0    142835      C   python3                                    11789MiB |
|    1    143208      C   python                                       429MiB |
+-----------------------------------------------------------------------------+
- a big table 2:
Mon Jul  5 20:17:42 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   60C    P0   137W / 300W |  23591MiB / 32510MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   34C    P0    42W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   30C    P0    41W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   34C    P0    41W / 300W |     11MiB / 32510MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0    142213      C   python3                                    11789MiB |
|    0    142835      C   python3                                    11789MiB |
+-----------------------------------------------------------------------------+
WARNING: infoROM is corrupted at gpu 0000:1A:00.0
- chart 1:
CONTAINER ID        IMAGE                                                                                                       COMMAND                  CREATED             STATUS              PORTS               NAMES
88623f1f4b41        192.103.2.201:5000/picos_mpi4y:cupy82-cuda92_python37_pytorch17_matplotlib33_scipy15_mrcfile12_skimage017   "sh -c 'cd /home/zhu…"   16 minutes ago      Up 16 minutes                           stupefied_feistel
e4b86dc7987d        192.103.2.201:5000/picos_mpi4y:cupy82-cuda92_python37_pytorch17_matplotlib33_scipy15_mrcfile12_skimage017   "sh -c 'cd /home/zhu…"   19 minutes ago      Up 19 minutes                           mystifying_hoover
- squeue后显示的 PARTITION指用的哪个队列，NODES指用的哪个节点，1个gpu01有4块V100卡，现在我们的程序用的单机单卡的版本，也可以用单机多卡的版本加速。
```
JOBID PARTITION             NAME             USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)
26969   SP-V100          fx-test     thunder_user  RUNNING    9:26:14 UNLIMITED      1 gpu01
26979 SP-GPUk40    subtract_test     thunder_user  RUNNING    5:54:51 UNLIMITED     16 fgpu[01-03,05-08,11-18,20]
27002    SP-CPU         ZRH_TOMO     thunder_user  RUNNING      26:00 UNLIMITED      1 cpu002
27004   SP-V100    ZJY_ML_Select     thunder_user  RUNNING       0:03 365-00:00:00      1 gpu02
```
- `x *= y`原位操作，指向内存不变。`x = x * y`另外分配一个内存空间，计算x*y，再赋值给x。如果x是broadcast的向量，会报错`x.shape`与`x*y.shape`不符合。
- 